{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tharunchandubatla/Tharun_INFO5731_Fall2023/blob/main/In_class_exercise_03_10082023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "## The third In-class-exercise (due on 11:59 PM 10/08/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2htC-oV70ne"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "classifying movie reviews as either \"positive\" or \"negative\" based on the sentiment expressed in the text.\n",
        "\n",
        "Bag of Words (BoW) Features:\n",
        "\n",
        "BoW represents the frequency of words in the text.\n",
        "Positive reviews may contain words like \"excellent,\" \"amazing,\" and \"enjoyable,\" while negative reviews may contain words like \"disappointing,\" \"awful,\" and \"bad.\"\n",
        "Why: BoW features help identify the presence of sentiment-related keywords in the reviews.\n",
        "\n",
        "Sentence Length Feature:\n",
        "\n",
        "The number of words in each sentence in the review.\n",
        "Short sentences may indicate a more straightforward sentiment expression.\n",
        "Why: Sentence length can be indicative of the review's complexity and potential sentiment.\n",
        "\n",
        "Punctuation Usage Feature:\n",
        "\n",
        "The frequency of exclamation marks (!) or question marks (?) in the review.\n",
        "Positive reviews may contain more exclamation marks, while negative reviews may contain more question marks or ellipses (...).\n",
        "Why: Punctuation usage can convey emotional intensity or uncertainty.\n",
        "\n",
        "Capitalization Feature:\n",
        "\n",
        "The percentage of words in uppercase in the review.\n",
        "Words in all caps may indicate strong sentiment, whether positive or negative.\n",
        "Why: Capitalization can emphasize emotional intensity.\n",
        "\n",
        "Positive and Negative Word Counts:\n",
        "\n",
        "Count the number of positive and negative sentiment words (e.g., \"good,\" \"bad\") in the review.\n",
        "Why: Counting specific sentiment words can directly capture sentiment orientation in the text.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae07dfc4-70f7-497f-e4e5-ed51f9bb9a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          text  bow_actors  bow_amazing  \\\n",
            "0         The movie was excellent! I loved it.           0            0   \n",
            "1  It was a terrible film... so disappointing.           0            0   \n",
            "2          An amazing movie with great actors!           1            1   \n",
            "3                This movie is bad and boring.           0            0   \n",
            "\n",
            "   bow_an  bow_and  bow_bad  bow_boring  bow_disappointing  bow_excellent  \\\n",
            "0       0        0        0           0                  0              1   \n",
            "1       0        0        0           0                  1              0   \n",
            "2       1        0        0           0                  0              0   \n",
            "3       0        1        1           1                  0              0   \n",
            "\n",
            "   bow_film  ...  bow_the  bow_this  bow_was  bow_with  sentence_length  \\\n",
            "0         0  ...        1         0        1         0           [7, 0]   \n",
            "1         1  ...        0         0        1         0  [5, 0, 0, 2, 0]   \n",
            "2         0  ...        0         0        0         1              [6]   \n",
            "3         0  ...        0         1        0         0           [6, 0]   \n",
            "\n",
            "   exclamation_marks  question_marks  capitalization  positive_words  \\\n",
            "0                  1               0        0.142857               1   \n",
            "1                  0               0        0.000000               0   \n",
            "2                  1               0        0.000000               2   \n",
            "3                  0               0        0.000000               0   \n",
            "\n",
            "   negative_words  \n",
            "0               0  \n",
            "1               1  \n",
            "2               0  \n",
            "3               1  \n",
            "\n",
            "[4 rows x 27 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string\n",
        "\n",
        "# Sample movie reviews\n",
        "reviews = [\n",
        "    \"The movie was excellent! I loved it.\",\n",
        "    \"It was a terrible film... so disappointing.\",\n",
        "    \"An amazing movie with great actors!\",\n",
        "    \"This movie is bad and boring.\",\n",
        "]\n",
        "\n",
        "# Create a DataFrame to store the reviews\n",
        "df = pd.DataFrame({'text': reviews})\n",
        "\n",
        "# Bag of Words (BoW) feature extraction\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Function to calculate sentence length\n",
        "def sentence_length(text):\n",
        "    sentences = text.split('.')\n",
        "    return [len(sentence.split()) for sentence in sentences]\n",
        "\n",
        "# Function to calculate punctuation usage\n",
        "def punctuation_usage(text):\n",
        "    exclamation_count = text.count('!')\n",
        "    question_count = text.count('?')\n",
        "    return exclamation_count, question_count\n",
        "\n",
        "# Function to calculate capitalization\n",
        "def capitalization(text):\n",
        "    uppercase_words = sum(1 for word in text.split() if word.isupper())\n",
        "    total_words = len(text.split())\n",
        "    return uppercase_words / total_words\n",
        "\n",
        "# Function to count positive and negative words\n",
        "def count_sentiment_words(text):\n",
        "    positive_words = ['excellent', 'amazing', 'loved', 'great']\n",
        "    negative_words = ['terrible', 'disappointing', 'bad', 'boring']\n",
        "\n",
        "    words = text.lower().split()\n",
        "    positive_count = sum(1 for word in words if word in positive_words)\n",
        "    negative_count = sum(1 for word in words if word in negative_words)\n",
        "\n",
        "    return positive_count, negative_count\n",
        "\n",
        "# Add BoW features to the DataFrame\n",
        "bow_feature_names = vectorizer.get_feature_names_out()\n",
        "for i, feature_name in enumerate(bow_feature_names):\n",
        "    df[f'bow_{feature_name}'] = X_bow[:, i].toarray()\n",
        "\n",
        "# Add other features to the DataFrame\n",
        "df['sentence_length'] = df['text'].apply(sentence_length)\n",
        "df['exclamation_marks'], df['question_marks'] = zip(*df['text'].apply(punctuation_usage))\n",
        "df['capitalization'] = df['text'].apply(capitalization)\n",
        "df['positive_words'], df['negative_words'] = zip(*df['text'].apply(count_sentiment_words))\n",
        "\n",
        "# Display the organized DataFrame with features\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2CRuXfV570ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fafb4eea-cc81-43a5-ce22-a743f5c05714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Feature  Chi-squared Score\n",
            "11             is           1.500000\n",
            "3             and           1.500000\n",
            "4             bad           1.500000\n",
            "5          boring           1.500000\n",
            "6   disappointing           1.500000\n",
            "18           this           1.500000\n",
            "16       terrible           1.500000\n",
            "15             so           1.500000\n",
            "17            the           1.333333\n",
            "10          great           1.333333\n",
            "13          loved           0.666667\n",
            "19     thoroughly           0.666667\n",
            "0          actors           0.666667\n",
            "1         amazing           0.666667\n",
            "8       excellent           0.666667\n",
            "7         enjoyed           0.666667\n",
            "2              an           0.666667\n",
            "21           with           0.666667\n",
            "9            film           0.083333\n",
            "12             it           0.055556\n",
            "14          movie           0.055556\n",
            "20            was           0.055556\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "# Sample movie reviews\n",
        "reviews = [\n",
        "    \"The movie was excellent! I loved it.\",\n",
        "    \"It was a terrible film... so disappointing.\",\n",
        "    \"An amazing movie with great actors!\",\n",
        "    \"This movie is bad and boring.\",\n",
        "    \"The film was great. I thoroughly enjoyed it.\",\n",
        "]\n",
        "\n",
        "# Create a DataFrame to store the reviews\n",
        "df = pd.DataFrame({'text': reviews, 'label': ['positive', 'negative', 'positive', 'negative', 'positive']})\n",
        "\n",
        "# Bag of Words (BoW) feature extraction\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Chi-squared feature selection\n",
        "chi2_scores, _ = chi2(X_bow, df['label'])\n",
        "\n",
        "# Create a DataFrame to store feature names and their importance scores\n",
        "feature_scores = pd.DataFrame({'Feature': vectorizer.get_feature_names_out(), 'Chi-squared Score': chi2_scores})\n",
        "\n",
        "# Sort features by importance in descending order\n",
        "sorted_features = feature_scores.sort_values(by='Chi-squared Score', ascending=False)\n",
        "\n",
        "# Display the sorted features\n",
        "print(sorted_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6XvYVBQXwXr",
        "outputId": "4d9e8791-2094-4526-a7e8-24614f76f4ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c93eb5-1b35-4247-abef-7670e30778cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Movie Reviews based on Text Similarity:\n",
            "                                        Review  Similarity\n",
            "0         The movie was excellent! I loved it.    0.741413\n",
            "3                This movie is bad and boring.    0.725099\n",
            "2          An amazing movie with great actors!    0.705845\n",
            "1  It was a terrible film... so disappointing.    0.613262\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Sample movie reviews\n",
        "reviews = [\n",
        "    \"The movie was excellent! I loved it.\",\n",
        "    \"It was a terrible film... so disappointing.\",\n",
        "    \"An amazing movie with great actors!\",\n",
        "    \"This movie is bad and boring.\",\n",
        "]\n",
        "\n",
        "# Query text\n",
        "query = \"I want to find reviews for a great movie.\"\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and embed the query using BERT\n",
        "qry_tkn = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "qry_embedding = model(**qry_tkn).last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "# Tokenize and embed movie reviews using BERT\n",
        "review_tokens = tokenizer(reviews, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "review_embeddings = model(**review_tokens).last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "# Calculate cosine similarity between the query and each movie review\n",
        "similarities = np.dot(qry_embedding, review_embeddings.T) / (np.linalg.norm(qry_embedding) * np.linalg.norm(review_embeddings, axis=1))\n",
        "\n",
        "# Create a DataFrame to store movie reviews and similarities\n",
        "result_data = pd.DataFrame({'Review': reviews, 'Similarity': similarities[0]})\n",
        "\n",
        "# Rank movie reviews by similarity in descending order\n",
        "result_data = result_data.sort_values(by='Similarity', ascending=False)\n",
        "\n",
        "# Display the ranked movie reviews\n",
        "print(\"Ranked Movie Reviews based on Text Similarity:\")\n",
        "print(result_data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}